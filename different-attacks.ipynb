{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#os.chdir('..')\n",
    "\n",
    "from attacks import influence_attack, anchoring_attack\n",
    "from datamodules import GermanCreditDatamodule, CompasDatamodule, DrugConsumptionDatamodule\n",
    "from fairness import FairnessLoss\n",
    "from trainingmodule import BinaryClassifier\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a **general attack function** that handles all different attack methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(dm, model, eps, method):\n",
    "    if method == 'IAF':\n",
    "        # Create adversarial loss according to Mehrabi et al.\n",
    "        bce_loss, fairness_loss = BCEWithLogitsLoss(), FairnessLoss(dm.get_sensitive_index())\n",
    "        adv_loss = lambda _model, X, y: (\n",
    "                bce_loss(_model(X), y.float()) + 0.1 * fairness_loss(X, *_model.get_params())\n",
    "        )\n",
    "        \n",
    "        # Create new training pipeline to use in influence attack\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=100,\n",
    "            gpus=1 if torch.cuda.is_available() else 0,\n",
    "            enable_model_summary=False,\n",
    "            enable_progress_bar=False,\n",
    "            log_every_n_steps=1,\n",
    "            callbacks=[EarlyStopping(monitor=\"train_acc\", mode=\"max\", patience=10)]\n",
    "        )\n",
    "\n",
    "        poisoned_dataset = influence_attack(\n",
    "            model=model,\n",
    "            datamodule=dm,\n",
    "            trainer=trainer,\n",
    "            adv_loss=adv_loss,\n",
    "            eps=eps,\n",
    "            eta=0.01,\n",
    "            attack_iters=100,\n",
    "        )\n",
    "    elif method in ['RAA', 'NRAA']:\n",
    "        poisoned_dataset = anchoring_attack(\n",
    "            D_c=dm.get_train_dataset(),\n",
    "            sensitive_idx=dm.get_sensitive_index(),\n",
    "            eps=eps,\n",
    "            tau=0,\n",
    "            sampling_method='random' if attack == 'RAA' else 'non-random',\n",
    "            attack_iters=1,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown attack {method}.')\n",
    "    \n",
    "    # Create deep copy of the original dataset and poison the copy\n",
    "    dm = deepcopy(dm)\n",
    "    dm.update_train_dataset(poisoned_dataset)\n",
    "\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a **nested dictionary**, which is convinient to store results for multiple datasets and metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "   return collections.defaultdict(nested_dict)\n",
    "\n",
    "results = nested_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, iterate over all possible combination of Figure 2 in Mehrabi et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoning German Credit dataset with IAF attack:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730ffbd460884a579d6da30db55fcf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'EOD': 0.01527780294418335,\n",
      " 'SPD': 0.2081504762172699,\n",
      " 'test_error': 0.29500001668930054}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/cvxpy/reductions/solvers/solving_chain.py:167: UserWarning: You are solving a parameterized problem that is not DPP. Because the problem is not DPP, subsequent solves will not be faster than the first one. For more information, see the documentation on Discplined Parametrized Programming, at\n",
      "\thttps://www.cvxpy.org/tutorial/advanced/index.html#disciplined-parametrized-programming\n",
      "  warnings.warn(dpp_error_msg)\n",
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/john/Desktop/MSc AI/FACT-AI/lightning_logs/version_29/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'EOD': 0.020833313465118408,\n",
      " 'SPD': 0.24639499187469482,\n",
      " 'test_error': 0.2799999713897705}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/john/Desktop/MSc AI/FACT-AI/lightning_logs/version_31/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'EOD': 0.04583334922790527,\n",
      " 'SPD': 0.24576802551746368,\n",
      " 'test_error': 0.3050000071525574}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /home/john/Desktop/MSc AI/FACT-AI/lightning_logs/version_33/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Exception ignored in: <function _releaseLock at 0x7ffb187335e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/john/anaconda3/envs/pytorchEnv/lib/python3.9/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Create Datamodules for all datasets\n",
    "german_credit_datamodule = GermanCreditDatamodule('data/', 200)\n",
    "compas_datamodule = CompasDatamodule('data/', 200)\n",
    "drug_consumption_datamodule = DrugConsumptionDatamodule('data/', 200)\n",
    "\n",
    "# Create Trainer\n",
    "\n",
    "for dm in [german_credit_datamodule, compas_datamodule, drug_consumption_datamodule]:\n",
    "    for method in ['IAF', 'RAA', 'NRAA']:\n",
    "        print(f'Poisoning {dm.get_dataset_name()} dataset with {method} attack:')\n",
    "        for eps in tqdm(np.arange(0, 1.1, 0.1)):\n",
    "            # Create a Binary Classifier model for each dataset\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=300,\n",
    "                gpus=1 if torch.cuda.is_available() else 0,\n",
    "                enable_model_summary=False,\n",
    "                enable_progress_bar=False,\n",
    "                log_every_n_steps=1,\n",
    "                callbacks=[EarlyStopping(monitor=\"train_acc\", mode=\"max\", patience=20)]\n",
    "            )\n",
    "            model = BinaryClassifier('LogisticRegression', dm.get_input_size(), lr=1e-3)\n",
    "            \n",
    "            # Create poisoned dataset\n",
    "            poisoned_dataset = attack(dm, model, eps, method)\n",
    "            \n",
    "            # Train on the poisoned dataset\n",
    "            trainer.fit(model, poisoned_dataset)\n",
    "            \n",
    "            # Save Accuracy and Fairness metrics\n",
    "            metrics = trainer.test(model, dm)[0]\n",
    "            results[dm.get_dataset_name()]['Test Error'][method][eps] = metrics['test_error']\n",
    "            results[dm.get_dataset_name()]['Statistical Parity'][method][eps] = metrics['SPD']\n",
    "            results[dm.get_dataset_name()]['Equality of Opportunity'][method][eps] = metrics['EOD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce plot styling of the original paper\n",
    "colors, markers = ['b', 'r', 'g'], ['s', 'x', '^']\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(20, 10))\n",
    "for i, dataset in enumerate(['German Credit', 'COMPAS', 'Drug Consumption']):\n",
    "    for j, metric in enumerate(['Test Error', 'Statistical Parity', 'Equality of Opportunity']):\n",
    "        for k, method in enumerate(['IAF', 'RAA', 'NRAA']):\n",
    "            ax[i, j].plot(\n",
    "                list(results[dataset][metric][method].keys()),\n",
    "                list(results[dataset][metric][method].values()),\n",
    "                c=colors[k],\n",
    "                marker=markers[k],\n",
    "                label = method,\n",
    "            )\n",
    "        \n",
    "        ax[i, j].set_xlabel('$\\epsilon$', fontweight='bold')\n",
    "        ax[i, j].set_ylabel(metric, fontweight='bold')\n",
    "        ax[i, j].set_title(dataset, fontweight='bold')\n",
    "        ax[i, j].legend(loc='upper left', ncol=3)\n",
    "        \n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.4, hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c11462fc89fac378f146398dd73443d105d4de5c614974541e5ab141425dc19"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dl1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
